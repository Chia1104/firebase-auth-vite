{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b70eb8-e3ee-4ee7-a2ce-0d1eb235c22f",
   "metadata": {},
   "source": [
    "# Base firestore\n",
    "\n",
    "* jump to relevant section after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355dc0fe-05c0-4701-aeb4-3c58a3d9df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,importlib\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "from IPython.display import display, Markdown,Image\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import firestore, storage, credentials\n",
    "\n",
    "\" Local includes\"\n",
    "from util import getFileName, getFileIsoDate, dir2df\n",
    "\n",
    "class Firestore:\n",
    "    def __init__(self,\n",
    "                 service_account_file=\"C:/i/auth/run-pix-092258e3cb1b.json\",\n",
    "                 bucket_name='run-pix.appspot.com'):\n",
    "        cred = credentials.Certificate(service_account_file)\n",
    "        try: self.app = firebase_admin.initialize_app(cred)\n",
    "        except: self.app = firebase_admin.get_app()\n",
    "        self.fstore=firestore.client()\n",
    "        self.storage=firebase_admin.storage\n",
    "        self.bucket=firebase_admin.storage.bucket(name=bucket_name, app=None) \n",
    "    def getDoc(self,path):\n",
    "        return self.fstore.document(path).get().to_dict()\n",
    "    def updateDoc(self,path,values):\n",
    "        return self.fstore.document(path).update(values)\n",
    "    \n",
    "    def collection(self):\n",
    "        return self.fstore\n",
    "    \n",
    "    def fs2Df(self,collPath):\n",
    "        def _f(x): # dict --> array of dicts\n",
    "            _={\"id\":x.id,'ref':x}\n",
    "            try: _.update(x.get().to_dict())\n",
    "            except: pass\n",
    "            return _\n",
    "        return pd.DataFrame([_f(_) for _ in self.fstore.collection(collPath).list_documents()])    \n",
    "    \"delete all subnodes\"\n",
    "    def delete_all_docs(self,collection):\n",
    "        for n in collection.get():\n",
    "            print(n.__dict__)\n",
    "            n._reference.delete()\n",
    "   \n",
    "runpix=Firestore()\n",
    "\n",
    "bucket=firebase_admin.storage.bucket(name='run-pix.appspot.com', app=None) \n",
    "\n",
    "class Race:\n",
    "    storage_prefixes='processed uploads thumbs'.split()\n",
    "    status=[]\n",
    "    blobs={}\n",
    "    bibs=[]\n",
    "    images=[]\n",
    "    readings=[]\n",
    "    def __init__(self,id):\n",
    "        self.fstore=firestore.client()\n",
    "        self.bucket=firebase_admin.storage.bucket(name='run-pix.appspot.com', app=None)         \n",
    "        self.id = id\n",
    "        for k,v in self.fstore.document(f'races/{id}').get().to_dict().items():\n",
    "          setattr(self,k,v)\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"<Race:{self.id} bibs:{len(self.bibs)} Images:{len(self.images)} readings:{len(self.readings)}\n",
    "        status: {self.status}\n",
    "        blobs:{[len(self.blobs[_].keys()) for _ in self.blobs.keys()]}>\n",
    "        \"\"\"\n",
    "    def getBlobs(self):\n",
    "        for folder in self.storage_prefixes:\n",
    "            self.blobs[folder]={b.name:{\"id\":b.id,\"name\":b.name,\"blob\":b,\"size\":b.size} \n",
    "                                    for b in bucket.list_blobs(prefix=f\"{folder}/{self.id}\")}\n",
    "        return self.blobs\n",
    "        # self.blobs_df=pd.DataFrame(\n",
    "    def getBibs(self):\n",
    "        df_d=[]\n",
    "            # .where(u'textAnnotations', u'==', [])\n",
    "        docs = runpix.fstore.collection(u'races',self.id,'bibs').stream()\n",
    "        for i,doc in enumerate(docs):\n",
    "            df_d.append(doc.to_dict())\n",
    "            # self.bibs=[_.get().to_dict() for _ in self.fstore.collection(f'races/{self.id}/bibs').list_documents()]\n",
    "        self.bibs=df_d\n",
    "        return df_d\n",
    "    def getReadings(self):\n",
    "        df_d=[]\n",
    "            # .where(u'textAnnotations', u'==', [])\n",
    "        docs =  runpix.fstore.collection(u'races',self.id,'readings').stream()\n",
    "        for i,doc in enumerate(docs):\n",
    "            df_d.append(doc.to_dict())\n",
    "            # self.bibs=[_.get().to_dict() for _ in self.fstore.collection(f'races/{self.id}/bibs').list_documents()]\n",
    "        self.readings=df_d\n",
    "        return df_d \n",
    "    def getimages(self,n=None):\n",
    "        df_d=[]\n",
    "            # .where(u'textAnnotations', u'==', [])\n",
    "        docs = runpix.fstore.collection(u'races',self.id,'images').stream()\n",
    "        for i,doc in enumerate(docs):\n",
    "            data_d=doc.to_dict()\n",
    "            ob=data_d\n",
    "            # ob={k:v for k,v in data_d.items() if k in 'imagePath texts'}\n",
    "            # if 'texts' in data_d:\n",
    "                # {'texts':data_d['texts']})\n",
    "                # print(f'{doc.id} => {len(data_d[\"texts\"])}')\n",
    "            # else:\n",
    "                # df_d.append({'texts':[]})\n",
    "                # print(f'{doc.id} => non textAnnotations')\n",
    "            df_d.append(ob)\n",
    "            if n!=None and i>n:\n",
    "                break\n",
    "        self.images=df_d\n",
    "        return df_d\n",
    "    def saveBib(self,bibData):\n",
    "      _bibData=bibData if isinstance (bibData,dict) else bibData.to_dict()\n",
    "      _bibData['Bib']=str(_bibData['Bib'])\n",
    "      _bibData['Name']=_bibData['Name'].upper()\n",
    "      _path=f\"races/{self.id}/bibs/{_bibData['Bib']}\"\n",
    "      runpix.fstore.document(_path).set(_bibData)\n",
    "      print(f\"loaded {_bibData['Bib']} {_bibData['Name']}\")\n",
    "\n",
    "    def deleteBlobs(self,folders=['thumbs']):\n",
    "        for folder in folders:\n",
    "            for b in race.blobs[folder]:\n",
    "                try:\n",
    "                    runpix.bucket.delete_blob(race.blobs[folder][b]['name'])\n",
    "                    print(race.blobs[folder][b]['name'])\n",
    "                except:\n",
    "                    print(f\"Error deleting {race.blobs[folder][b]['name']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599fd7f-76a8-4259-bdca-cd9182f6d2ac",
   "metadata": {},
   "source": [
    "# Load up a race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75dc917e-feae-4557-8129-53a2a9a89300",
   "metadata": {},
   "outputs": [],
   "source": [
    "raceId=\"mychoice23apr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df2f906-98c0-4b0d-b5b8-b20190260770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Race:mychoice23apr bibs:739 Images:1832 readings:2994\n",
       "        status: ['started', 'stopped']\n",
       "        blobs:[1809, 1870, 1808]>\n",
       "        "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "race= Race(raceId)\n",
    "race.getBlobs()\n",
    "race.getBibs()\n",
    "race.getimages()\n",
    "race.getReadings()\n",
    "\n",
    "# x=[_.get().to_dict() for _ in self.fstore.collection(f'races/{self.id}/bibs').list_documents()]\n",
    "race"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6563a63e-3c1c-4baf-9f4e-a9da35bc377d",
   "metadata": {},
   "source": [
    "CPU times: total: 62.5 ms\n",
    "Wall time: 4.8 s\n",
    "\n",
    "<Race:mychoice23apr bibs:0 Images:32 readings:46\n",
    "        status: ??\n",
    "        blobs:[31, 32, 31]>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08f5002-514a-4375-a126-4425f2867998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-04-09T01:03:59.150Z~5~avinashmane$gmail.com~capture.png',\n",
       " '2023-04-09T01:04:37.350Z~5~avinashmane$gmail.com~capture.png',\n",
       " '2023-04-09T01:09:21.150Z~5~avinashmane$gmail.com~capture.png',\n",
       " '2023-04-09T01:11:24.150Z~5~avinashmane$gmail.com~capture.png',\n",
       " '2023-04-09T01:17:09.650Z~5~avinashmane$gmail.com~capture.png',\n",
       " '2023-04-09T01:25:03.550Z~5~avinashmane$gmail.com~capture.png',\n",
       " '2023-04-09T01:29:40.550Z~5~avinashmane$gmail.com~capture.png',\n",
       " '2023-04-09T01:53:29.750Z~VENUE~avinashmane$gmail.com~IMG_20230409_072326.jpg',\n",
       " '2023-04-09T01:53:39.950Z~VENUE~avinashmane$gmail.com~IMG_20230409_072338.jpg',\n",
       " '2023-04-09T02:31:16.950Z~VENUE~breakingcoconut$gmail.com~IMG_20230409_080116.jpg',\n",
       " '2023-04-09T16:05:16.650Z~VENUE~jparagj$gmail.com~1P6A7097.jpg',\n",
       " '2023-04-09T16:17:47.450Z~VENUE~jparagj$gmail.com~1P6A7265.jpg',\n",
       " '2023-04-09T16:30:07.450Z~VENUE~jparagj$gmail.com~1P6A7419.jpg',\n",
       " '2023-04-09T16:40:53.650Z~VENUE~jparagj$gmail.com~1P6A7553.jpg',\n",
       " '2023-04-09T17:05:17.950Z~VENUE~jparagj$gmail.com~1P6A7869.jpg',\n",
       " '2023-04-09T17:06:58.850Z~VENUE~jparagj$gmail.com~1P6A7890.jpg',\n",
       " '2023-04-09T17:10:27.850Z~VENUE~jparagj$gmail.com~1P6A7937.jpg',\n",
       " '2023-04-09T17:44:46.250Z~VENUE~jparagj$gmail.com~1P6A8292.jpg']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def searchImage(search):\n",
    "    return [_['imagePath'] for _ in race.images if search in _['imagePath']]\n",
    "# def setfireStorage\n",
    "display(searchImage(\"50Z\"))\n",
    "img0=searchImage(\"16.950Z\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3652e3bf-1d07-409d-93cf-4e637550c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60ecc5-5f4d-41b7-a22a-e43c341af324",
   "metadata": {},
   "source": [
    "# display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b1613f11-810f-4104-b652-df548ec9c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from matplotlib.pyplot import imshow, figure\n",
    "# from matplotlib import pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "# im.show()\n",
    "class rpImage:\n",
    "    # img0=f\"races/{race.id}/images/{img0}\"\n",
    "        \n",
    "    def __init__(self,img=\"races/mychoice23apr/images/2023-04-09T16:04:59.925Z~VENUE~jparagj$gmail.com~1P6A7093.jpg\"):\n",
    "        self.fsPath=img\n",
    "        folder='uploads'\n",
    "        self.imgBlobPath=\"/\".join([folder,race.id,img.split(\"/\")[-1]])\n",
    "        display(self.imgBlobPath)\n",
    "        self.fs=runpix.getDoc(img)\n",
    "        \n",
    "        self.blob=runpix.bucket.blob(self.imgBlobPath)\n",
    "        self.im = Image.open(io.BytesIO(self.blob.download_as_bytes()))\n",
    "   \n",
    "    def mapxy(self,xy): return xy['x'],xy['y']\n",
    "    def mapBoundingPoly(self,x):\n",
    "        arr=[]\n",
    "        for i in [0,2]:\n",
    "            arr.append(self,mapxy(x['vertices'][i]))\n",
    "        return arr \n",
    "    def testMap(self):\n",
    "        for _a in self.fs['textAnnotations']:\n",
    "            print(_a['description'][:10],mapBoundingPoly(_a['boundingPoly']))\n",
    "            \n",
    "    def show(self,inline=True):\n",
    "        if inline:\n",
    "            figure(figsize = (12,8))\n",
    "            imshow(self.im)   \n",
    "        else:\n",
    "            self.im.show()\n",
    "    def drawAnnotations(self):\n",
    "        # use a truetype font\n",
    "        self.font = ImageFont.truetype(\"arial.ttf\", 40)\n",
    "        self.draw = ImageDraw.Draw(self.im)            \n",
    "        # xy=[(x0, y0), (x1, y1)] or [x0, y0, x1, y1]\n",
    "        # draw.rectangle([100,200,400,500], fill=None, outline=None, width=5)\n",
    "        for i,_a in enumerate(self.fs['textAnnotations']):\n",
    "            # print(_a['description'][:10],mapBoundingPoly(_a['boundingPoly']))\n",
    "            # fnt = ImageFont.truetype(\"Pillow/Tests/fonts/FreeMono.ttf\", 40)\n",
    "            self.draw.rectangle(mapBoundingPoly(_a['boundingPoly']), fill=None, outline=\"#ffff0014\", width=5)\n",
    "            for i in range(4):\n",
    "                # print(f\"draw.line([{mapxy(_a['boundingPoly']['vertices'][i]),mapxy(_a['boundingPoly']['vertices'][(i+1)%4])}], fill=None, width=0, joint=None)\")\n",
    "                self.draw.line([mapxy(_a['boundingPoly']['vertices'][i]),mapxy(_a['boundingPoly']['vertices'][(i+1)%4])], \n",
    "                               fill=\"#ffff0014\", width=20,joint=None) #(255, 255, 0, 128)\n",
    "            # draw text, half opacity\n",
    "            try:\n",
    "                self.draw.text(mapxy(_a['boundingPoly']['vertices'][0]), _a['description'], \n",
    "                               font=self.font, fill=\"#ff000014\")\n",
    "            except:\n",
    "                print('err')\n",
    "                pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4c9e66ed-a75a-47ab-89e3-1c8ad67c2f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uploads/mychoice23apr/2023-04-09T16:10:15.695Z~VENUE~jparagj$gmail.com~1P6A7169.jpg'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=rpImage('races/mychoice23apr/images/2023-04-09T16:10:15.695Z~VENUE~jparagj$gmail.com~1P6A7169.jpg')\n",
    "# img.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a08930df-968c-427f-a89f-c75687636c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img.show()\n",
    "\n",
    "img.drawAnnotations()\n",
    "img.show(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a91e69-3478-46cc-b62c-b816c4b149c4",
   "metadata": {},
   "source": [
    "# Move metadata and Annotations to image metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "59d30369-a52e-4f53-b42a-74306130f592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4637"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.blob.metadata=img.fs['metadata']\n",
    "len(str(img.fs['metadata']))\n",
    "len(str(img.fs['textAnnotations']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57647e7-a3e7-47c4-a49d-53a01908e32f",
   "metadata": {},
   "source": [
    "# test with Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b9a49487-2ec0-4e85-a8a0-a65c19b8928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS='c:/i/auth/run-pix-092258e3cb1b.json'\n"
     ]
    }
   ],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS='c:/i/auth/run-pix-092258e3cb1b.json'\n",
    "import os\n",
    "# credential_path = r\"c:\\i\\auth\\run-pix-092258e3cb1b.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'c:/i/auth/run-pix-092258e3cb1b.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "247ab84c-7d83-4f4c-9994-dceb43b96597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crop Hint: 0\n",
      "[(1018, 0), (3013, 0), (3013, 3023), (1018, 3023)]\n",
      "\n",
      "Crop Hint: 1\n",
      "[(1260, 0), (2772, 0), (2772, 3023), (1260, 3023)]\n",
      "\n",
      "Crop Hint: 2\n",
      "[(504, 0), (3528, 0), (3528, 3023), (504, 3023)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[bounding_poly {\n",
       "  vertices {\n",
       "    x: 1018\n",
       "  }\n",
       "  vertices {\n",
       "    x: 3013\n",
       "  }\n",
       "  vertices {\n",
       "    x: 3013\n",
       "    y: 3023\n",
       "  }\n",
       "  vertices {\n",
       "    x: 1018\n",
       "    y: 3023\n",
       "  }\n",
       "}\n",
       "confidence: 0.59375\n",
       "importance_fraction: 0.660000086\n",
       ", bounding_poly {\n",
       "  vertices {\n",
       "    x: 1260\n",
       "  }\n",
       "  vertices {\n",
       "    x: 2772\n",
       "  }\n",
       "  vertices {\n",
       "    x: 2772\n",
       "    y: 3023\n",
       "  }\n",
       "  vertices {\n",
       "    x: 1260\n",
       "    y: 3023\n",
       "  }\n",
       "}\n",
       "confidence: 0.59375\n",
       "importance_fraction: 0.5\n",
       ", bounding_poly {\n",
       "  vertices {\n",
       "    x: 504\n",
       "  }\n",
       "  vertices {\n",
       "    x: 3528\n",
       "  }\n",
       "  vertices {\n",
       "    x: 3528\n",
       "    y: 3023\n",
       "  }\n",
       "  vertices {\n",
       "    x: 504\n",
       "    y: 3023\n",
       "  }\n",
       "}\n",
       "confidence: 0.59375\n",
       "importance_fraction: 1\n",
       "]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_crop_hints(path,aspectratios):\n",
    "    \"\"\"Detects crop hints in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    im = Image.open(io.BytesIO(content))\n",
    "    draw = ImageDraw.Draw(im)          \n",
    "    \n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    crop_hints_params = vision.CropHintsParams(aspect_ratios=aspectratios)\n",
    "    image_context = vision.ImageContext(\n",
    "        crop_hints_params=crop_hints_params)\n",
    "\n",
    "    response = client.crop_hints(image=image, image_context=image_context)\n",
    "    hints = response.crop_hints_annotation.crop_hints\n",
    "\n",
    "    for n, hint in enumerate(hints):\n",
    "        print('\\nCrop Hint: {}'.format(n))\n",
    "\n",
    "        vertices = [(vertex.x,vertex.y)\n",
    "                    for vertex in hint.bounding_poly.vertices]\n",
    "        draw.rectangle([vertices[0],vertices[2],], fill=None, outline=\"#ffff0014\", width=5)\n",
    "        print(vertices)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "        \n",
    " \n",
    "\n",
    "    # imshow(im)\n",
    "    im.show()\n",
    "        \n",
    "    return hints\n",
    "        \n",
    "detect_crop_hints(r\"C:\\temp\\a21.jpg\",[.66,.5,1])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f62efa94-1705-47ab-a405-f873a1879b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'oauth2client'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[214], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This snippet has been automatically generated and should be regarded as a\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# code template only.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# It will require modifications to work:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#   client as shown in:\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#   https://googleapis.dev/python/google-api-core/latest/client_options.html\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vision\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moauth2client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice_account\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ServiceAccountCredentials\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'oauth2client'"
     ]
    }
   ],
   "source": [
    "# This snippet has been automatically generated and should be regarded as a\n",
    "# code template only.\n",
    "# It will require modifications to work:\n",
    "# - It may require correct/in-range values for request initialization.\n",
    "# - It may require specifying regional endpoints when creating the service\n",
    "#   client as shown in:\n",
    "#   https://googleapis.dev/python/google-api-core/latest/client_options.html\n",
    "from google.cloud import vision\n",
    "# from oauth2client.service_account import ServiceAccountCredentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0eab24cc-b56d-452a-af64-cdf62396182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient(credentials=\"/i/auth/run-pix-092258e3cb1b.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ba5c0820-584b-432f-8007-01a49d43f636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAnnotateImageRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mignore_unknown_fields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Request for performing Google Cloud Vision API tasks over a\n",
       "user-provided image, with user-requested features, and with\n",
       "context information.\n",
       "\n",
       "Attributes:\n",
       "    image (google.cloud.vision_v1.types.Image):\n",
       "        The image to be processed.\n",
       "    features (MutableSequence[google.cloud.vision_v1.types.Feature]):\n",
       "        Requested features.\n",
       "    image_context (google.cloud.vision_v1.types.ImageContext):\n",
       "        Additional context that may accompany the\n",
       "        image.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\sw\\py310nb_env\\lib\\site-packages\\google\\cloud\\vision_v1\\types\\image_annotator.py\n",
       "\u001b[1;31mType:\u001b[0m           MessageMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vision.AnnotateImageRequest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14ad83-4806-4da7-ad90-a3f7c313ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize request argument(s)\n",
    "request = vision.BatchAnnotateImagesRequest(\n",
    ")\n",
    "\n",
    "# Make the request\n",
    "response = client.batch_annotate_images(request=request)\n",
    "\n",
    "# Handle the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e273730d-991e-4fdc-b3d1-9a2060fa4d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-vision\n",
      "  Downloading google_cloud_vision-3.4.1-py2.py3-none-any.whl (444 kB)\n",
      "     ---------------------------------------- 0.0/444.3 kB ? eta -:--:--\n",
      "     ------------------------------------  440.3/444.3 kB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  440.3/444.3 kB 13.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 444.3/444.3 kB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-cloud-vision) (2.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-cloud-vision) (1.22.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-cloud-vision) (4.21.12)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.58.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.16.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.28.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.51.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.51.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\sw\\py310nb_env\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\sw\\py310nb_env\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\sw\\py310nb_env\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\sw\\py310nb_env\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\sw\\py310nb_env\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\sw\\py310nb_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (0.4.8)\n",
      "Installing collected packages: google-cloud-vision\n",
      "Successfully installed google-cloud-vision-3.4.1\n"
     ]
    }
   ],
   "source": [
    "# import argparse\n",
    "# import io\n",
    "\n",
    "# from google.cloud import vision\n",
    "# from google.cloud.vision import types\n",
    "!pip install google-cloud-vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94832c61-105a-48ab-8130-1dda9c5c6f93",
   "metadata": {},
   "source": [
    "# Races "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5046e0-8563-49f0-9979-afcb92504e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "races=runpix.fstore.collection('races')\n",
    "\"list all races\"\n",
    "\n",
    "df_races=fs2Df('races')\n",
    "races.where(\"Location\",\"==\",\"GT\").select(\"Name Location\".split())."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7caf1b7-413d-438a-9150-f4b5b36ba3a2",
   "metadata": {},
   "source": [
    "## list all blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe624bc-6a76-4c21-a0ad-3613b2b8d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blob[:3].apply(lambda x: x['name'].split(\"/\").pop(),\n",
    "                  axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f698262-b1ff-4363-a3f8-8ee12052e0de",
   "metadata": {},
   "source": [
    "## other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ae13f-9a61-4005-a108-c6dcfc0ed31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"query examples\"\n",
    "{_.id:_.to_dict() for _ in races.where('Location','==','GT').stream()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da203fde-fbd5-4f3b-b4d1-68ec8be8e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COPY RACE\n",
    "\"\"\"\n",
    "def copyRace(fromId,toId):\n",
    "    fromRace=races.document(fromId).get().to_dict()\n",
    "    print(fromRace)\n",
    "    return races.document(toId).set(fromRace)\n",
    "\n",
    "# copyRace('mychoice23apr','mychoice23mar')\n",
    "# copyRace('mychoice23mar','mychoice23jan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baccf94-1784-4f16-80d1-27fef6f2d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNewRace(id):\n",
    "    raceData = {'Date': \"YYYY-MM-DD\", \n",
    "                'Waypoints': ['venue', 'start', 'end'], \n",
    "                'Name': 'Default Race Year Month', \n",
    "                'Location': 'DC',\n",
    "                'bibPatterm': r'\\d\\d\\d\\d'\n",
    "               }\n",
    "    update_time, city_ref = races.document(id).set(raceData)\n",
    "    print(f'Added document with id {city_ref.id}')\n",
    "    \n",
    "addNewRace('mychoice23apr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2defba3a-f34f-4bf8-8902-32eb07a3f14e",
   "metadata": {},
   "source": [
    "# Overall Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20c36d-9489-48cb-bf72-0fbb1327094c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_races.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64be9b1-4d71-4bac-81d2-42401ababb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDir(x):\n",
    "    return pd.Series(x.split('/')[:-1]+3*[''])[:3]\n",
    "    \n",
    "def printBlobSummary(df):\n",
    "    df['size_mb']=df['size']/10**6\n",
    "    return pd.concat([df,df.name.apply(getDir)],axis=1)#).str.split(\"[\\-/]\",n=2,regex=True,expand=True)\n",
    "\n",
    "printBlobSummary(df_blob).pivot_table(index=[0,1],values=\"size_mb\",aggfunc=['sum','count']).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed3b9e-10a6-4510-b35e-27cf5469c9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afdf180c-08c3-4944-93be-21afbd413065",
   "metadata": {},
   "source": [
    "# Images (Storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eeb902-9bf9-4c57-a38b-c5484746ce7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_raceImages=Race('mychoice23mar').getRaceImages()\n",
    "# old df_raceImages=getRaceImages('mychoice23mar')\n",
    "\n",
    "display(df_raceImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab77aefc-3667-4b7e-bbc5-6c2e987e3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    images without texts\n",
    "\"\"\"\n",
    "# df_raceImages.query(\"texts.isna()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523d671-d3ad-411f-bd21-681a46edf46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raceImages['texts'].explode().value_counts().reset_index().style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71bdda-a06c-4c86-b7e1-4f52b4c40c1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c0055-6c28-4563-a1b9-dae03dc3f342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed62c57-c889-4b76-a26c-6964940d6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, b in enumerate(blobs):\n",
    "#     print (i,b.name)\n",
    "all_blobs_l=df_blob.name.apply(lambda x : x.split(\"~\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332b7b5-ab6c-4d23-a3a2-43a0a193e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"signed URL\"\n",
    "blobs[3].generate_signed_url(pd.Timestamp.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe17229-d2c0-41ed-9b11-f74c5c1ba576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from base64 import b64decode\n",
    "base64_data = blocs[1].download_as_bytes() #\"iVBORw0KGgoAAAANSUhEUgAABL ...  the rest of data \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7b818-63a5-47c4-b135-7b8d826958fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base64_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753447ed-8f60-41ff-947b-47eb4fec49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(b64decode(base64_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222a461-6970-404a-bb01-2618057ada74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def newname(x):\n",
    "#     arr=x.split('/')\n",
    "#     arr[]\n",
    "# gs://run-pix.appspot.com/thumbs/2023-02-12T01:25:41.084Z^venue^avinashmane$gmail.com^20230212_065538.jpg/2023-02-12T01:25:41.084Z^venue^avinashmane$gmail.com^20230212_065538.jpg\n",
    "for i,b in enumerate(blobs):\n",
    "    if 'thumbs/2023' in b.name :#and b.content_type=='image/jpeg':        \n",
    "        newName=\"thumbs/mychoice23feb/\"+b.name.split('/')[-1]\n",
    "        print(i,b.name,newName)\n",
    "        bucket.copy_blob(b,bucket,newName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc40d3-4e1f-4602-b87e-23bcbb9b431e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\".generate_signed_url() needs date\"\n",
    "new_id=\"run-pix.appspot.com/thumbs/mychoice23feb/2023-02-12T01:25:41.084Z^venue^avinashmane$gmail.com^20230212_065538.jpg/1678882880166980\"\n",
    "blobs[72].content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b7e66-fb2c-46b1-b48d-ab1a4b39c9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket.copy_blob()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc551f4e-560e-49bd-81b3-a2844416ecd3",
   "metadata": {},
   "source": [
    "# Bulk Bib Upload\n",
    "\n",
    "Data copied from clipboard from Excel:\n",
    "\n",
    "Columns copied are (case sensitive)\n",
    "* Bib\n",
    "* Name\n",
    "* Status\n",
    "* Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a3a1e-21ab-4179-8e2e-900d418d8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raceId = 'werun2023'\n",
    "display(Markdown(f\"## Creating Bib list for {raceId}\"))\n",
    "bibs=runpix.fstore.collection(f'races/{raceId}/bibs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa99309-11df-4969-aec5-88eef7c657d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Check Race details\"\n",
    "def dictUtf(mydict): \n",
    "    return {k: str(v).encode(\"utf-8\") for k,v in mydict.items()}\n",
    "\n",
    "races.document(raceId).get().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6e198-d889-4da4-8881-2ebaf7687033",
   "metadata": {},
   "source": [
    "##  Copy the data\n",
    "Data copied from clipboard from Excel:\n",
    "\n",
    "Columns copied are (case sensitive)\n",
    "* Bib\n",
    "* Name\n",
    "* Status\n",
    "* Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce4984-bc9c-4d3a-8f9c-67b3e910834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_startlist=pd.read_clipboard()\n",
    "display(\"columns in clipboard:\",df_startlist.columns)\n",
    "if 'BIB Number' in df_startlist:\n",
    "    df_startlist=df_startlist.rename(columns={'BIB Number': 'Bib', 'fullname': 'Name',  })\n",
    "    df_startlist['Status']='From sheet'\n",
    "    df_startlist['Race']='My Choice'\n",
    "_required_columns='Bib\tName\tStatus\tRace'.split('\\t')\n",
    "_found_columns = [_x for _x in _required_columns if  _x in df_startlist.columns]\n",
    "display(\"columns found \",_found_columns)\n",
    "if len(_found_columns)<len(_required_columns): print(\"PLEASE WAIT \"+('X'*10+' ')*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ccf42-0672-4cf8-9499-cd0eb71dce58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd48b5-a733-40c8-8c7e-c6f4de0ab3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_startlist=df_startlist[_required_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb825a9c-03ee-4087-a5d9-d684d4a2146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"code\"\n",
    "bibtoDict=lambda x: x.to_dict()\n",
    "bibtoDict(df_startlist.loc[0,:])  # test\n",
    "\n",
    "def saveBibtoRace(bibData,bibsCollection):\n",
    "    _bibData=bibtoDict(bibData)\n",
    "    _bibData['Bib']=str(_bibData['Bib'])\n",
    "    bibsCollection.document(_bibData['Bib']\n",
    "                           ).set(_bibData)\n",
    "saveBibtoRace(df_startlist.loc[0,:],bibsCollection=bibs,)  # test    \n",
    "# df_startlist.apply(, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fff8d2-84ca-4cb1-9df9-d1525cd9746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" upload all bibs\"\n",
    "# df_startlist.apply(bibtoDict, axis=1)  #test\n",
    "df_startlist.apply(lambda x: saveBibtoRace(x,bibs), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360d7cd-4c41-482f-be26-ea70e4cd9c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bibs.count().get()\n",
    "# len(list( bibs.list_documents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e11ad-d567-4aa3-815b-0766e58295dd",
   "metadata": {},
   "source": [
    "# Update images to bibs \n",
    "\n",
    "Add list of images to the bibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9060db4-fdca-4038-b291-d36230f899e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0573b8f3-65c7-4475-9dbc-617c50769bbd",
   "metadata": {},
   "source": [
    "# Bulk Upload images list_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18984692-3260-47f4-b17a-2adc0935a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "cfg={}\n",
    "cfg.update(yaml.safe_load(r\"\"\"\n",
    "uploads:\n",
    "    werun2023:\n",
    "        #path: D:\\We Run 2023\\JPEG\n",
    "        path: D:\\We Run 2023\\Vaibhav\\JPEG\n",
    "        fileRange: [\"\",\"XX\"]\n",
    "        waypoint: venue\n",
    "        userid: vaibhav\n",
    "    mychoice23feb:\n",
    "        path: D:\\umesh\\D K D  2023 2\\Untitled Export\n",
    "        waypoint: general\n",
    "        userid: bcoconut\n",
    "    mychoice23mar:\n",
    "        path: D:\\DKD-Parag\\DKD 2023\\DCIM\\New folder\n",
    "        waypoint: general\n",
    "        userid: bcoconut\n",
    "\"\"\"))\n",
    "\n",
    "\n",
    "raceId='mychoice23mar'\n",
    "cfg['uploads'][raceId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bfd39d-577e-4c8a-8c0d-1912f558ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir=dir2df(cfg['uploads'][raceId]['path'])\n",
    "# df_dir['type root'.split()].value_counts()                 \n",
    "print(f\"{raceId} uploading from '{cfg['uploads'][raceId]['path']}',df_dir:{df_dir.shape}\\n\",df_dir.root.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a0c30-403d-4723-b1ce-19f1a99e4a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ea3f5-aea1-4745-92c2-7ac11e542854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Manually rename to retrigger the processing...\n",
    "- You can change waypoint from venue to general\n",
    "\"\"\"\n",
    "\"* Storage: /uploads/race/time~wpt~user~loc~file    # uploaded images\"\n",
    "i=0\n",
    "folder=f'uploads/{raceId}/'\n",
    "import concurrent.futures \n",
    "def getNewfileName(file,\n",
    "                   user=cfg['uploads'][raceId]['userid'],\n",
    "                   place=cfg['uploads'][raceId]['waypoint']):\n",
    "    return \"~\".join([getFileIsoDate(file),place,user,getFileName(file)])\n",
    "\n",
    "def uploadFile(root,name):\n",
    "    path=os.path.join(root, name)\n",
    "    new=folder+getNewfileName(path)\n",
    "    # blob=bucket.blob(folder+name) #used when renaming to diff filenames\n",
    "    blob=bucket.blob(new)\n",
    "\n",
    "    if blob.exists():\n",
    "        print(stats['files'],'blob exists/rewriting',name,new)\n",
    "        blob.rewrite(blob)\n",
    "    else:\n",
    "        threads.append({new:executor.submit(blob.upload_from_filename,path)})\n",
    "        print(stats['files'],f'uploading {path} to {new}', )\n",
    "        # blob.upload_from_filename(path)\n",
    "        \n",
    "\n",
    "stats={\"files\":0,'upl':0}\n",
    "prefix=f'processed/{raceId}'\n",
    "\n",
    "all_blobs_l=[blob.name.split(\"~\")[-1] for blob in bucket.list_blobs(prefix=prefix)]\n",
    "executor=concurrent.futures.ThreadPoolExecutor(max_workers=5)\n",
    "threads=[]\n",
    "\n",
    "for lot in cfg['uploads'].keys():\n",
    "    _dir=cfg['uploads'][lot]['path'].lower()\n",
    "    print(\"raceId\",lot,_dir,f\"{len(all_blobs_l)} in {prefix}  ====================\")\n",
    "    # for root, dirs, files in os.walk(cfg['uploads'][lot]['path'], topdown=False):\n",
    "    for i,d in df_dir.query(f\"(type=='file') and (root.str.lower() == @_dir)\"\n",
    "                             ).iterrows():\n",
    "        stats['files']+=1\n",
    "        if not d.path in all_blobs_l:\n",
    "            uploadFile(d.root,d.path)\n",
    "            stats['upl']+=1\n",
    "        else:\n",
    "            print(prefix,d.path ,\"found\")\n",
    "            pass\n",
    "        # if (stats['files']>20): raise  #stopper\n",
    "    print(f\"{lot}: {stats['files']} files\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c78d4-7c5c-4e9a-b62b-3fe4eb736e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    find object from gcs\n",
    "    \n",
    "\"\"\"\n",
    "display(Markdown(\"## rename blob\"))\n",
    "# bucket.blob('uploads/werun2023/_L3A3192.jpg').rewrite\n",
    "# blob.rewrite?\n",
    "bname='2023-03-13T19:23:14.739819~general~vaibhav~_L3A2997.jpg'\n",
    "def renameBlob(bname):\n",
    "    bucket.rename_blob(bucket.blob(bname),folder+bname)\n",
    "# renameBlob(bname) \n",
    "\"use 2: existence check\"\n",
    "bucket.blob('error in getDownloadURL thumbs/werun2023/2023-03-13T19:23:42.882584~general~vaibhav~_L3A3007.jpg').exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc901d-b835-4167-9ff4-d13f54bbeb19",
   "metadata": {},
   "source": [
    "## check storage file (which folder?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2194b-0a52-46f1-bf49-a5f1f9bc8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check existance\n",
    "# _path=r\"processed/mychoice23feb/2023-02-12T01:28:29.364Z^venue^avinashmane$gmail.com^20230212_065828.jpg\"\n",
    "_path=\"processed/werun2023/2023-03-13T19:25:41.041091~general~vaibhav~_L3A3047.jpg\"\n",
    "[_,_raceId,_name]=_path.split(\"/\")\n",
    "\n",
    "print(_,_raceId,_name,)\n",
    "for r in ['default',_raceId]:\n",
    "    for t in 'processed thumbs uploads'.split():\n",
    "        newName=\"/\".join([t,r,_name])\n",
    "        _blob=bucket.blob(newName)\n",
    "        print(newName,_blob.exists() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2468ca-49d1-4d13-8249-f3c8a9892695",
   "metadata": {},
   "source": [
    "## check all images in the race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4857ab-aadd-41ac-a337-ebfc7388af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images=fs2Df(f'races/{raceId}/images')\n",
    "df_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3cbe4-61ea-4119-a083-28715764d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_images['imagePath'].value_counts()\n",
    "def checkBlobs(x,types=['processed','thumbs']):\n",
    "    return [bucket.blob(f'{typ}/{raceId}/{x}').exists() \n",
    "                                        for typ in types]\n",
    "def moveBlob(x,typ='thumbs'): #'processed',\n",
    "    correctName=f'{typ}/{raceId}/{x}'\n",
    "    if not bucket.blob(correctName).exists() :\n",
    "        defaultThumb=bucket.blob(f'{typ}/default/{x}')\n",
    "        \n",
    "        if defaultThumb.exists():\n",
    "            bucket.rename_blob(defaultThumb,f'{typ}/{raceId}/{x}')\n",
    "            print(f\"{correctName} not exists, moving from default\")\n",
    "        else:\n",
    "            procBlob=bucket.blob(f'uploads/{raceId}/{x}')\n",
    "            if procBlob.exists():\n",
    "                print(f\"{procBlob.name} rename the blob to retrigger functions\")\n",
    "                procBlob.rewrite(procBlob)\n",
    "                \n",
    "            else:\n",
    "                procBlob.upload_from_filename(path4file+x.split(\"~\")[-1])\n",
    "                print(f\"need to upload {x}\")\n",
    "    else:\n",
    "        print(f\"{correctName} exists\")\n",
    "\n",
    "path4file=r\"D:\\We Run 2023\\JPEG\\\\\"\n",
    "display(raceId, path4file)\n",
    "df_images['imagePath'].apply(lambda x: moveBlob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63abc60-ff96-4234-89f1-583182863bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteFSimages4missingBlobs(x,types=['processed','thumbs']):\n",
    "    chk = checkBlobs(x.imagePath)\n",
    "    if not any(chk):\n",
    "        print(chk,x,x.imagePath)\n",
    "        x.ref.delete()\n",
    "df_images.apply(deleteFSimages4missingBlobs ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4acd9-3ebd-4f58-8e78-5393b7ca5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blob.query(\"name.str.contains('G017')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4b2a9-0ad3-4df1-ba8c-9a42fb1022f0",
   "metadata": {},
   "source": [
    "# move from mychoice23APR to Ahimsa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d5f81-f6b5-4e6a-8fc6-d33cd1268d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mychoice23apr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652f2f6-3bca-4dbe-85c9-62d9efd957ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# allDocs=\n",
    "\"\"\" COPY FIREBASE DATA \"\"\"\n",
    "for x in mychoice23apr.fstore.collection('races/mychoice23apr/images').stream():\n",
    "    if '2023-04-02' in x.id:\n",
    "        newDict = x.to_dict()\n",
    "        newDict['metadata']['imagePath']=newDict['metadata']['imagePath'].replace('mychoice23apr','ahimsarun2023')\n",
    "        # {k:(v.replace() \n",
    "        #            if isinstance(v,str) else v)\n",
    "        #            for (k,v) in .items()}\n",
    "        mychoice23apr.fstore.document(f'races/ahimsarun2023/images/{x.id}').set(newDict)\n",
    "        mychoice23apr.fstore.document(f'races/mychoice23apr/images/{x.id}').delete()\n",
    "        print (x.id)\n",
    "    else:\n",
    "        print ('skipping', x.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a56d3d-d591-4594-a9a3-eca1a35e7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" move blobs from on race to another \"\n",
    "def copy_blob(name):\n",
    "    # name=\"processed/mychoice23apr/2023-03-18T02:39:47.304Z~venue~avinashmane$gmail.com~capture.jpg\"\n",
    "    new_name=name.replace(\"mychoice23apr\",\"ahimsarun2023\")\n",
    "    print(\"renaming\",name,new_name)\n",
    "    blob=mychoice23apr.storage.blob(name)\n",
    "    if blob.exists():\n",
    "        runpix.bucket.copy_blob(blob,runpix.bucket,new_name=new_name)\n",
    "        pass\n",
    "    \n",
    "for r in \"mychoice23apr\".split():\n",
    "    for folder in \"processed\".split():\n",
    "        prefix=f\"{folder}/{r}/2023-04-02\"\n",
    "        for i,blob in enumerate(mychoice23apr.storage.list_blobs(prefix=prefix)):\n",
    "            # print(blob.name)\n",
    "            copy_blob(blob.name)\n",
    "            blob.delete()\n",
    "            if i>100: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c02fb2-ba2e-42b9-b6d1-e01ed756f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.delete()\n",
    "Image(blob.download_as_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2210a-1191-47e7-846c-55e83a6f0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_blob('processed/mychoice23apr/2023-04-02T00:43:14.291Z~venue~avinashmane$gmail.com~capture.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb3346-8406-4fae-a57c-00bc842dd972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19824f9e-ae30-4cd1-83ff-b792e8498f5d",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fae2ee-3175-4eb6-8ba1-ebc5b995efa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27839f-5c4c-4a68-8f97-526a2ab0ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.blob('processed/werun2023/2023-03-13T19:25:41.041091~general~vaibhav~_L3A3047.jpg').public_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a505f-b15e-44c1-96c0-afcedcd6338e",
   "metadata": {},
   "source": [
    "#Files to be deleted\n",
    "\n",
    "raceId mychoice23feb d:\\umesh\\d k d  2023 2\\untitled export 3 in processed/mychoice23feb\n",
    "1 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5534.jpg to uploads/werun2023/2023-03-16T13:57:47.954854~general~bcoconut~1P6A5534.jpg\n",
    "2 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5535.jpg to uploads/werun2023/2023-03-16T13:57:48.517336~general~bcoconut~1P6A5535.jpg\n",
    "3 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5536.jpg to uploads/werun2023/2023-03-16T13:57:48.861077~general~bcoconut~1P6A5536.jpg\n",
    "4 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5537.jpg to uploads/werun2023/2023-03-16T13:57:49.329810~general~bcoconut~1P6A5537.jpg\n",
    "5 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5538.jpg to uploads/werun2023/2023-03-16T13:57:49.829797~general~bcoconut~1P6A5538.jpg\n",
    "6 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5539.jpg to uploads/werun2023/2023-03-16T13:57:50.673521~general~bcoconut~1P6A5539.jpg\n",
    "7 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5540.jpg to uploads/werun2023/2023-03-16T13:57:51.251623~general~bcoconut~1P6A5540.jpg\n",
    "8 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5541.jpg to uploads/werun2023/2023-03-16T13:57:52.095346~general~bcoconut~1P6A5541.jpg\n",
    "9 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5542.jpg to uploads/werun2023/2023-03-16T13:57:52.798449~general~bcoconut~1P6A5542.jpg\n",
    "10 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5543.jpg to uploads/werun2023/2023-03-16T13:57:53.782791~general~bcoconut~1P6A5543.jpg\n",
    "11 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5544.jpg to uploads/werun2023/2023-03-16T13:57:54.360898~general~bcoconut~1P6A5544.jpg\n",
    "12 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5545.jpg to uploads/werun2023/2023-03-16T13:57:54.907755~general~bcoconut~1P6A5545.jpg\n",
    "13 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5546.jpg to uploads/werun2023/2023-03-16T13:57:55.392115~general~bcoconut~1P6A5546.jpg\n",
    "14 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5547.jpg to uploads/werun2023/2023-03-16T13:57:55.892099~general~bcoconut~1P6A5547.jpg\n",
    "15 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5548.jpg to uploads/werun2023/2023-03-16T13:57:56.204588~general~bcoconut~1P6A5548.jpg\n",
    "16 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5549.jpg to uploads/werun2023/2023-03-16T13:57:56.626450~general~bcoconut~1P6A5549.jpg\n",
    "17 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5550.jpg to uploads/werun2023/2023-03-16T13:57:57.032689~general~bcoconut~1P6A5550.jpg\n",
    "18 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5551.jpg to uploads/werun2023/2023-03-16T13:57:57.501423~general~bcoconut~1P6A5551.jpg\n",
    "19 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5552.jpg to uploads/werun2023/2023-03-16T13:57:57.938908~general~bcoconut~1P6A5552.jpg\n",
    "20 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5553.jpg to uploads/werun2023/2023-03-16T13:57:58.438893~general~bcoconut~1P6A5553.jpg\n",
    "21 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5554.jpg to uploads/werun2023/2023-03-16T13:57:59.110745~general~bcoconut~1P6A5554.jpg\n",
    "22 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5555.jpg to uploads/werun2023/2023-03-16T13:57:59.876345~general~bcoconut~1P6A5555.jpg\n",
    "23 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5556.jpg to uploads/werun2023/2023-03-16T13:58:00.516953~general~bcoconut~1P6A5556.jpg\n",
    "24 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5557.jpg to uploads/werun2023/2023-03-16T13:58:00.923188~general~bcoconut~1P6A5557.jpg\n",
    "25 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5558.jpg to uploads/werun2023/2023-03-16T13:58:01.376301~general~bcoconut~1P6A5558.jpg\n",
    "26 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5559.jpg to uploads/werun2023/2023-03-16T13:58:01.907535~general~bcoconut~1P6A5559.jpg\n",
    "27 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5560.jpg to uploads/werun2023/2023-03-16T13:58:02.610633~general~bcoconut~1P6A5560.jpg\n",
    "28 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5561.jpg to uploads/werun2023/2023-03-16T13:58:03.048121~general~bcoconut~1P6A5561.jpg\n",
    "29 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5562.jpg to uploads/werun2023/2023-03-16T13:58:03.532478~general~bcoconut~1P6A5562.jpg\n",
    "30 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5563.jpg to uploads/werun2023/2023-03-16T13:58:03.969964~general~bcoconut~1P6A5563.jpg\n",
    "31 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5564.jpg to uploads/werun2023/2023-03-16T13:58:04.469950~general~bcoconut~1P6A5564.jpg\n",
    "32 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5565.jpg to uploads/werun2023/2023-03-16T13:58:05.126179~general~bcoconut~1P6A5565.jpg\n",
    "33 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5566.jpg to uploads/werun2023/2023-03-16T13:58:05.501164~general~bcoconut~1P6A5566.jpg\n",
    "34 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5567.jpg to uploads/werun2023/2023-03-16T13:58:05.923026~general~bcoconut~1P6A5567.jpg\n",
    "35 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5568.jpg to uploads/werun2023/2023-03-16T13:58:06.313642~general~bcoconut~1P6A5568.jpg\n",
    "36 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5569.jpg to uploads/werun2023/2023-03-16T13:58:06.766748~general~bcoconut~1P6A5569.jpg\n",
    "37 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5570.jpg to uploads/werun2023/2023-03-16T13:58:07.094863~general~bcoconut~1P6A5570.jpg\n",
    "38 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5571.jpg to uploads/werun2023/2023-03-16T13:58:07.594847~general~bcoconut~1P6A5571.jpg\n",
    "39 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5572.jpg to uploads/werun2023/2023-03-16T13:58:07.938586~general~bcoconut~1P6A5572.jpg\n",
    "40 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5573.jpg to uploads/werun2023/2023-03-16T13:58:08.282328~general~bcoconut~1P6A5573.jpg\n",
    "41 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5575.jpg to uploads/werun2023/2023-03-16T13:58:08.735436~general~bcoconut~1P6A5575.jpg\n",
    "42 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5576.jpg to uploads/werun2023/2023-03-16T13:58:09.141680~general~bcoconut~1P6A5576.jpg\n",
    "43 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5577.jpg to uploads/werun2023/2023-03-16T13:58:09.672905~general~bcoconut~1P6A5577.jpg\n",
    "44 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5579.jpg to uploads/werun2023/2023-03-16T13:58:10.047894~general~bcoconut~1P6A5579.jpg\n",
    "45 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5580.jpg to uploads/werun2023/2023-03-16T13:58:10.376008~general~bcoconut~1P6A5580.jpg\n",
    "46 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5581.jpg to uploads/werun2023/2023-03-16T13:58:10.704123~general~bcoconut~1P6A5581.jpg\n",
    "47 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5582.jpg to uploads/werun2023/2023-03-16T13:58:11.110360~general~bcoconut~1P6A5582.jpg\n",
    "48 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5583.jpg to uploads/werun2023/2023-03-16T13:58:11.454099~general~bcoconut~1P6A5583.jpg\n",
    "49 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5585.jpg to uploads/werun2023/2023-03-16T13:58:11.922834~general~bcoconut~1P6A5585.jpg\n",
    "50 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5586.jpg to uploads/werun2023/2023-03-16T13:58:12.297822~general~bcoconut~1P6A5586.jpg\n",
    "51 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5587.jpg to uploads/werun2023/2023-03-16T13:58:12.657186~general~bcoconut~1P6A5587.jpg\n",
    "52 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5588.jpg to uploads/werun2023/2023-03-16T13:58:12.969674~general~bcoconut~1P6A5588.jpg\n",
    "53 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5589.jpg to uploads/werun2023/2023-03-16T13:58:13.438409~general~bcoconut~1P6A5589.jpg\n",
    "54 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5590.jpg to uploads/werun2023/2023-03-16T13:58:13.735275~general~bcoconut~1P6A5590.jpg\n",
    "55 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5591.jpg to uploads/werun2023/2023-03-16T13:58:14.079020~general~bcoconut~1P6A5591.jpg\n",
    "56 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5592.jpg to uploads/werun2023/2023-03-16T13:58:14.407129~general~bcoconut~1P6A5592.jpg\n",
    "57 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5594.jpg to uploads/werun2023/2023-03-16T13:58:14.703994~general~bcoconut~1P6A5594.jpg\n",
    "58 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5595.jpg to uploads/werun2023/2023-03-16T13:58:15.000858~general~bcoconut~1P6A5595.jpg\n",
    "59 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5596.jpg to uploads/werun2023/2023-03-16T13:58:15.391475~general~bcoconut~1P6A5596.jpg\n",
    "60 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5597.jpg to uploads/werun2023/2023-03-16T13:58:15.813334~general~bcoconut~1P6A5597.jpg\n",
    "61 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5598.jpg to uploads/werun2023/2023-03-16T13:58:16.360190~general~bcoconut~1P6A5598.jpg\n",
    "62 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5599.jpg to uploads/werun2023/2023-03-16T13:58:16.703928~general~bcoconut~1P6A5599.jpg\n",
    "63 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5600.jpg to uploads/werun2023/2023-03-16T13:58:16.953921~general~bcoconut~1P6A5600.jpg\n",
    "64 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5601.jpg to uploads/werun2023/2023-03-16T13:58:17.250787~general~bcoconut~1P6A5601.jpg\n",
    "65 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5602.jpg to uploads/werun2023/2023-03-16T13:58:17.563277~general~bcoconut~1P6A5602.jpg\n",
    "66 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5603.jpg to uploads/werun2023/2023-03-16T13:58:17.844517~general~bcoconut~1P6A5603.jpg\n",
    "67 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5604.jpg to uploads/werun2023/2023-03-16T13:58:18.219508~general~bcoconut~1P6A5604.jpg\n",
    "68 uploading D:\\umesh\\D K D  2023 2\\Untitled Export\\1P6A5605.jpg to uploads/werun2023/2023-03-16T13:58:18.516370~general~bcoconut~1P6A5605.jpg"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f26c6c3e6779aa43ee1c2715d332bcf59648a29de16f854ab6767dd41ea1d325"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
